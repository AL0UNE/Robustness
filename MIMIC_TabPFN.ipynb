{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install TabPFN\n",
    "!git clone https://github.com/PriorLabs/tabpfn\n",
    "!pip install -e tabpfn\n",
    "\n",
    "# TabPFN Community installs optional functionalities around the TabPFN model\n",
    "# These include post-hoc ensembles, interpretability tools, and more\n",
    "!git clone https://github.com/PriorLabs/tabpfn-extensions\n",
    "!pip install -e tabpfn-extensions[post_hoc_ensembles,interpretability,hpo]\n",
    "\n",
    "# Install TabICL\n",
    "!pip install git+https://github.com/soda-inria/tabicl.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, StratifiedKFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Deep learning methods\n",
    "from tabpfn_extensions.post_hoc_ensembles.sklearn_interface import AutoTabPFNClassifier\n",
    "from tabpfn_extensions.rf_pfn import (\n",
    "    RandomForestTabPFNClassifier,\n",
    ")\n",
    "\n",
    "from tabpfn_extensions import TabPFNClassifier\n",
    "\n",
    "from tabicl import TabICLClassifier\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import pickle\n",
    "import timeit\n",
    "\n",
    "import torch\n",
    "if not torch.cuda.is_available():\n",
    "    raise SystemError('GPU device not found. For fast training, please enable GPU. See section above for instructions.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_3 = pd.read_csv('mimic_3_processed.csv')\n",
    "mimic_4 = pd.read_csv('mimic_4_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'age', 'heartrate_max', 'heartrate_min', 'sysbp_max', 'sysbp_min', 'tempc_max', 'tempc_min', \n",
    "    'urineoutput', 'bun_min', 'bun_max', 'wbc_min', 'wbc_max',\n",
    "    'potassium_min', 'potassium_max', 'sodium_min', 'sodium_max', 'bicarbonate_min', 'bicarbonate_max', \n",
    "    'mingcs', 'aids', 'hem', 'mets', 'admissiontype',\n",
    "#    'pao2fio2_vent_min', 'bilirubin_min', 'bilirubin_max',\n",
    "]\n",
    "\n",
    "cont_features = [\n",
    "    'age', 'heartrate_max', 'heartrate_min', 'sysbp_max', 'sysbp_min', 'tempc_max', 'tempc_min', \n",
    "    'urineoutput', 'bun_min', 'bun_max', 'wbc_min', 'wbc_max',\n",
    "    'potassium_min', 'potassium_max', 'sodium_min', 'sodium_max', 'bicarbonate_min', 'bicarbonate_max', \n",
    "    'mingcs'\n",
    "#    'pao2fio2_vent_min', 'bilirubin_min', 'bilirubin_max',\n",
    "]\n",
    "\n",
    "cat_features = [\n",
    "    'aids', 'hem', 'mets', 'admissiontype'\n",
    "]\n",
    "\n",
    "outcome = [\n",
    "    'hospital_mortality'\n",
    "]\n",
    "\n",
    "socio_demographic = [\n",
    "    'insurance', 'marital_status', 'ethnicity', 'language', 'gender'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mimic_3[features]\n",
    "y = mimic_3['hospital_mortality']\n",
    "y_proxy = mimic_3['icustay_expire_flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(df, n_folds = n_folds):\n",
    "    df_true_prob = df['Prob true'].explode().groupby(level=0).apply(lambda x: pd.Series(x.values)).unstack()\n",
    "    df_true_prob.columns = ['Prob_true_fold_' + str(i+1) for i in range(n_folds)]\n",
    "    df_pred_prob = df['Prob pred'].explode().groupby(level=0).apply(lambda x: pd.Series(x.values)).unstack()\n",
    "    df_pred_prob.columns = ['Prob_pred_fold_' + str(i+1) for i in range(n_folds)]\n",
    "    df = df.drop(['Prob true', 'Prob pred'], axis=1)\n",
    "    df = pd.concat([df, df_true_prob, df_pred_prob], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory(directory_name):\n",
    "    try:\n",
    "        os.mkdir(directory_name)\n",
    "        print(f\"Directory '{directory_name}' created successfully.\")\n",
    "    except FileExistsError:\n",
    "        print(f\"Directory '{directory_name}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_directory('results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_base = TabPFNClassifier(\n",
    "    ignore_pretraining_limits=True,\n",
    "    inference_config = {\"SUBSAMPLE_SAMPLES\": 10000} # Needs to be set low so that not OOM on fitting intermediate nodes\n",
    ")\n",
    "\n",
    "tabpfn_tree_clf = RandomForestTabPFNClassifier(\n",
    "    tabpfn=clf_base,\n",
    "    verbose=1,\n",
    "    max_predict_time=60, # Will fit for one minute\n",
    "    fit_nodes=True, # Wheather or not to fit intermediate nodes\n",
    "    adaptive_tree=True, # Whather or not to validate if adding a leaf helps or not\n",
    "  )\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'TabPFN RF': tabpfn_tree_clf,\n",
    "    'TabICL': TabICLClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_name = list(models.keys())\n",
    "\n",
    "n_models = len(models_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_crossvalidation = Parallel(n_jobs=-1, verbose=1)(delayed(cross_val_score)(model, X, y, scoring='roc_auc', cv=n_folds) \n",
    "                                          for model in models.values()\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_crossvalidation_df = pd.DataFrame(\n",
    "    score_crossvalidation, index=models_name, columns=[\"fold_\"+str(i+1) for i in np.arange(n_folds)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_crossvalidation_df.to_csv('results/result_crossvalidation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_label_noise_levels = np.linspace(0, 1, 11)\n",
    "targeted_label_noise_levels = np.linspace(0, 1, 10, endpoint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_label_noise(y_noisy, noise_level):\n",
    "    idx_change_outcome = np.random.rand(len(y_noisy))<noise_level\n",
    "    y_noisy[idx_change_outcome] = 1-y_noisy\n",
    "    \n",
    "    return y_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_noise(model_name, model, noise_level, train_idx, val_idx, noise_type='random'):\n",
    "\n",
    "    X_train, X_val = X.loc[train_idx], X.loc[val_idx]\n",
    "    y_train, y_val = y.loc[train_idx], y.loc[val_idx]\n",
    "    y_proxy_train = y_proxy.loc[train_idx]\n",
    "    y_train_noisy = y_train.copy()\n",
    "    \n",
    "    if noise_type=='random':\n",
    "        y_train_noisy = add_label_noise(y_train_noisy, noise_level)\n",
    "    elif noise_type=='0to1':\n",
    "        y_train_noisy[y_train_noisy==0] = add_label_noise(y_train_noisy[y_train_noisy==0], noise_level)\n",
    "    elif noise_type=='1to0':\n",
    "        y_train_noisy[y_train_noisy==1] = add_label_noise(y_train_noisy[y_train_noisy==1], noise_level)\n",
    "    elif noise_type=='conditional':\n",
    "        age_train_perc = X_train.age.rank(pct=True)\n",
    "        swap_by_age = np.random.binomial(1, p=age_train_perc**noise_level, size=len(age_train_perc))\n",
    "        y_train_noisy = y_train_noisy*(swap_by_age) + (1-y_train_noisy)*(1-swap_by_age)\n",
    "    elif noise_type=='proxy':\n",
    "        y_train_noisy = y_train_noisy*(1-noise_level) + y_proxy_train*noise_level\n",
    "        \n",
    "    \n",
    "    model.fit(X_train, y_train_noisy)\n",
    "\n",
    "    y_pred = model.predict_proba(X_val)[:,1]\n",
    "    prob_true, prob_pred = calibration_curve(y_val, y_pred)\n",
    "    \n",
    "    return model_name, noise_level, roc_auc_score(y_score=y_pred, y_true=y_val), brier_score_loss(y_true=y_val, y_proba=y_pred), prob_true, prob_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_random_label_noise = Parallel(n_jobs=-1, verbose=1)(delayed(label_noise)(model_name, model, noise_level, train_idx, val_idx, noise_type='random') \n",
    "                                          for model_name, model in models.items()\n",
    "                                          for noise_level in random_label_noise_levels\n",
    "                                          for train_idx, val_idx in kf.split(X)\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_label_noise_01 = Parallel(n_jobs=-1, verbose=1)(delayed(label_noise)(model_name, model, noise_level, train_idx, val_idx, noise_type='0to1') \n",
    "                                          for model_name, model in models.items()\n",
    "                                          for noise_level in targeted_label_noise_levels\n",
    "                                          for train_idx, val_idx in kf.split(X)\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_label_noise_10 = Parallel(n_jobs=-1, verbose=1)(delayed(label_noise)(model_name, model, noise_level, train_idx, val_idx, noise_type='1to0') \n",
    "                                          for model_name, model in models.items()\n",
    "                                          for noise_level in targeted_label_noise_levels\n",
    "                                          for train_idx, val_idx in kf.split(X)\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_label_noise_age = Parallel(n_jobs=-1, verbose=1)(delayed(label_noise)(model_name, model, noise_level, train_idx, val_idx, noise_type='conditional') \n",
    "                                          for model_name, model in models.items()\n",
    "                                          for noise_level in random_label_noise_levels\n",
    "                                          for train_idx, val_idx in kf.split(X)\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_label_noise_proxy = Parallel(n_jobs=-1, verbose=1)(delayed(label_noise)(model_name, model, noise_level, train_idx, val_idx, noise_type='proxy') \n",
    "                                          for model_name, model in models.items()\n",
    "                                          for noise_level in [0, 1]\n",
    "                                          for train_idx, val_idx in kf.split(X)\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'results/label_noise/'\n",
    "create_directory(directory)\n",
    "\n",
    "label_noise_levels = {\n",
    "    'random': random_label_noise_levels,\n",
    "    '0to1': targeted_label_noise_levels,\n",
    "    '1to0': targeted_label_noise_levels,\n",
    "    'age': random_label_noise_levels,\n",
    "    'proxy': [0,1]\n",
    "}\n",
    "\n",
    "results_label_noise = {\n",
    "    \"random\": results_random_label_noise, \n",
    "    \"0to1\": results_label_noise_01, \n",
    "    \"1to0\": results_label_noise_10,\n",
    "    \"age\": results_label_noise_age, \n",
    "    \"proxy\": results_label_noise_proxy\n",
    "}\n",
    "\n",
    "for k, result in results_label_noise.items():\n",
    "    df_results = pd.DataFrame(result, columns=['Model', 'Noise level', 'AUC', 'Brier score', 'Prob true', 'Prob pred'])\n",
    "    df_results.to_csv(directory+k+'.csv', index=False)\n",
    "    df_results = process_df(df_results, n_folds)    \n",
    "    df_results.to_csv(directory+k+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measurement noise\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_noise_level = np.linspace(0,1,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_measurement_noise(X, noise_level, feature_type='cont & cat'):\n",
    "\n",
    "    X_noisy = X.copy()\n",
    "    size = X_noisy.shape\n",
    "    \n",
    "    if 'cont' in feature_type:\n",
    "        for j in cont_features:\n",
    "            std_j = X_noisy[j].std()\n",
    "            noise_j = np.random.normal(scale=std_j*noise_level, size=size[0])\n",
    "            X_noisy[j] = X_noisy[j] + noise_j\n",
    "            \n",
    "    if 'cat' in feature_type:\n",
    "        for j in cat_features:\n",
    "            max_xj = X_noisy[j].max()\n",
    "            min_xj = X_noisy[j].min()\n",
    "            mask = np.random.binomial(1, noise_level, size=size[0])\n",
    "            noise = np.random.randint(0, max_xj, size=size[0]) ## only works for consecutive integers\n",
    "            noise[noise == X_noisy[j].values] = (noise[noise == X_noisy[j].values] + 1) % max_xj\n",
    "            X_noisy[j] = np.where(mask, noise, X_noisy[j])\n",
    "    \n",
    "    return X_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_noise(model_name, model, noise_level, train_idx, val_idx, which_set=\"Train\", feature_type='cont & cat'):\n",
    "\n",
    "    X_train, X_val = X.loc[train_idx], X.loc[val_idx]\n",
    "    y_train, y_val = y.loc[train_idx], y.loc[val_idx]\n",
    "    \n",
    "    if which_set==\"Train\":\n",
    "        X_train = add_measurement_noise(X_train, noise_level, feature_type)\n",
    "    if which_set==\"Val\":\n",
    "        X_val = add_measurement_noise(X_val, noise_level, feature_type)\n",
    "    if which_set==\"Train_Val\":\n",
    "        X_train = add_measurement_noise(X_train, noise_level, feature_type)\n",
    "        X_val = add_measurement_noise(X_val, noise_level, feature_type)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict_proba(X_val)[:,1]\n",
    "    prob_true, prob_pred = calibration_curve(y_val, y_pred)\n",
    "    \n",
    "    return model_name, noise_level, roc_auc_score(y_score=y_pred, y_true=y_val), brier_score_loss(y_true=y_val, y_proba=y_pred), prob_true, prob_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_input_noise_train = Parallel(n_jobs=-1, verbose=1)(delayed(input_noise)(model_name, model, noise_level, train_idx, val_idx) \n",
    "                                          for model_name, model in models.items()\n",
    "                                          for noise_level in input_noise_level\n",
    "                                          for train_idx, val_idx in kf.split(X)\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_input_noise_val = Parallel(n_jobs=-1, verbose=1)(delayed(input_noise)(model_name, model, noise_level, train_idx, val_idx, which_set='Val') \n",
    "                                          for model_name, model in models.items()\n",
    "                                          for noise_level in input_noise_level\n",
    "                                          for train_idx, val_idx in kf.split(X)\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_input_noise_all = Parallel(n_jobs=-1, verbose=1)(delayed(input_noise)(model_name, model, noise_level, train_idx, val_idx, which_set='Train_Val') \n",
    "                                          for model_name, model in models.items()\n",
    "                                          for noise_level in input_noise_level\n",
    "                                          for train_idx, val_idx in kf.split(X)\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_input_noise_train_cont = Parallel(n_jobs=-1, verbose=1)(delayed(input_noise)(model_name, model, noise_level, train_idx, val_idx, feature_type='cont') \n",
    "                                          for model_name, model in models.items()\n",
    "                                          for noise_level in input_noise_level\n",
    "                                          for train_idx, val_idx in kf.split(X)\n",
    "                                         )\n",
    "results_input_noise_val_cont = Parallel(n_jobs=-1, verbose=1)(delayed(input_noise)(model_name, model, noise_level, train_idx, val_idx, which_set='Val', feature_type='cont') \n",
    "                                          for model_name, model in models.items()\n",
    "                                          for noise_level in input_noise_level\n",
    "                                          for train_idx, val_idx in kf.split(X)\n",
    "                                         )\n",
    "results_input_noise_all_cont = Parallel(n_jobs=-1, verbose=1)(delayed(input_noise)(model_name, model, noise_level, train_idx, val_idx, which_set='Train_Val', feature_type='cont') \n",
    "                                          for model_name, model in models.items()\n",
    "                                          for noise_level in input_noise_level\n",
    "                                          for train_idx, val_idx in kf.split(X)\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_input_noise_train_cat = Parallel(n_jobs=-1, verbose=1)(delayed(input_noise)(model_name, model, noise_level, train_idx, val_idx, feature_type='cat') \n",
    "                                          for model_name, model in models.items()\n",
    "                                          for noise_level in input_noise_level\n",
    "                                          for train_idx, val_idx in kf.split(X)\n",
    "                                         )\n",
    "results_input_noise_val_cat = Parallel(n_jobs=-1, verbose=1)(delayed(input_noise)(model_name, model, noise_level, train_idx, val_idx, which_set='Val', feature_type='cat') \n",
    "                                          for model_name, model in models.items()\n",
    "                                          for noise_level in input_noise_level\n",
    "                                          for train_idx, val_idx in kf.split(X)\n",
    "                                         )\n",
    "results_input_noise_all_cat = Parallel(n_jobs=-1, verbose=1)(delayed(input_noise)(model_name, model, noise_level, train_idx, val_idx, which_set='Train_Val', feature_type='cat') \n",
    "                                          for model_name, model in models.items()\n",
    "                                          for noise_level in input_noise_level\n",
    "                                          for train_idx, val_idx in kf.split(X)\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'results/input_noise/'\n",
    "create_directory(directory)\n",
    "\n",
    "results_input_noise = {\n",
    "    \"train\": results_input_noise_train, \n",
    "    \"val\": results_input_noise_val, \n",
    "    \"all\": results_input_noise_all,\n",
    "    \"train_cont\": results_input_noise_train_cont, \n",
    "    \"val_cont\": results_input_noise_val_cont, \n",
    "    \"all_cont\": results_input_noise_all_cont, \n",
    "    \"train_cat\": results_input_noise_train_cat, \n",
    "    \"val_cat\": results_input_noise_val_cat, \n",
    "    \"all_cat\": results_input_noise_all_cat, \n",
    "}\n",
    "\n",
    "for k,result in results_input_noise.items():\n",
    "    df_results = pd.DataFrame(result, columns=['Model', 'Noise level', 'AUC', 'Brier score', 'Prob true', 'Prob pred'])\n",
    "    df_results.to_csv(directory+k+'.csv', index=False)\n",
    "    df_results = process_df(df_results, n_folds)    \n",
    "    df_results.to_csv(directory+k+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalance data\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalance_ratio = np.linspace(1, 0, 10, endpoint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imbalance_data(model_name, model, imbalance_ratio, train_idx, val_idx):\n",
    "\n",
    "    X_train, X_val = X.loc[train_idx], X.loc[val_idx]\n",
    "    y_train, y_val = y.loc[train_idx], y.loc[val_idx]\n",
    "\n",
    "    X_train_negative = X_train.loc[y_train==0].sample(frac = imbalance_ratio)\n",
    "    y_train_negative = y_train.loc[X_train_negative.index]\n",
    "    X_train_balanced = pd.concat([X_train_negative, X_train.loc[y_train==1]])\n",
    "    y_train_balanced = pd.concat([y_train_negative, y_train.loc[y_train==1]])\n",
    "\n",
    "    model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "    y_pred = model.predict_proba(X_val)[:,1]\n",
    "    prob_true, prob_pred = calibration_curve(y_val, y_pred)\n",
    "    \n",
    "    return model_name, imbalance_ratio, roc_auc_score(y_score=y_pred, y_true=y_val), brier_score_loss(y_true=y_val, y_proba=y_pred), prob_true, prob_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_imbalance_data = Parallel(n_jobs=-1, verbose=1)(delayed(imbalance_data)(model_name, model, ratio, train_idx, val_idx) \n",
    "                                          for model_name, model in models.items()\n",
    "                                          for ratio in imbalance_ratio\n",
    "                                          for train_idx, val_idx in kf.split(X)\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'results/imbalance_data/'\n",
    "create_directory(directory)\n",
    "\n",
    "df_results = pd.DataFrame(results_imbalance_data, columns=['Model', 'Noise level', 'Brier score', 'AUC', 'Prob true', 'Prob pred'])\n",
    "df_results.to_csv(directory+'imbalance_data.csv', index=False)\n",
    "df_results = process_df(df_results, n_folds)    \n",
    "df_results.to_csv(directory+'imbalance_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_ratio = np.linspace(0, 1, 11, endpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_features(X, prop=0.5, feat_to_shuffle=None):\n",
    "    X_noisy = X.copy()\n",
    "    size = X_noisy.shape\n",
    "\n",
    "    n_feat_to_shuffle = int(size[1]*prop)\n",
    "    if feat_to_shuffle is None:\n",
    "        feat_to_shuffle = np.random.choice(X_noisy.columns, size=n_feat_to_shuffle, replace=False)\n",
    "    X_noisy[feat_to_shuffle] = X_noisy[feat_to_shuffle].apply(np.random.permutation)\n",
    "    \n",
    "    return X_noisy, feat_to_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_features(model_name, model, noise_level, train_idx, val_idx, which_set=\"Train\"):\n",
    "\n",
    "    X_train, X_val = X.loc[train_idx], X.loc[val_idx]\n",
    "    y_train, y_val = y.loc[train_idx], y.loc[val_idx]\n",
    "    \n",
    "    if which_set==\"Train\":\n",
    "        X_train, _ = shuffle_features(X_train, noise_level)\n",
    "    if which_set==\"Val\":\n",
    "        X_val, _ = shuffle_features(X_val, noise_level)\n",
    "    if which_set==\"Train_Val\":\n",
    "        X_train, feat_to_shuffle = shuffle_features(X_train, noise_level)\n",
    "        X_val, _ = shuffle_features(X_val, noise_level, feat_to_shuffle=feat_to_shuffle)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict_proba(X_val)[:,1]\n",
    "    prob_true, prob_pred = calibration_curve(y_val, y_pred)\n",
    "    \n",
    "    return model_name, noise_level, roc_auc_score(y_score=y_pred, y_true=y_val), brier_score_loss(y_true=y_val, y_proba=y_pred), prob_true, prob_pred    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_shuffled_data_train = Parallel(n_jobs=-1, verbose=1)(delayed(permutation_features)(model_name, model, ratio, train_idx, val_idx, which_set='Train') \n",
    "                                          for model_name, model in models.items()\n",
    "                                          for ratio in shuffle_ratio\n",
    "                                          for train_idx, val_idx in kf.split(X)\n",
    "                                         )\n",
    "results_shuffled_data_val = Parallel(n_jobs=-1, verbose=1)(delayed(permutation_features)(model_name, model, ratio, train_idx, val_idx, which_set='Val') \n",
    "                                          for model_name, model in models.items()\n",
    "                                          for ratio in shuffle_ratio\n",
    "                                          for train_idx, val_idx in kf.split(X)\n",
    "                                         )\n",
    "results_shuffled_data_all = Parallel(n_jobs=-1, verbose=1)(delayed(permutation_features)(model_name, model, ratio, train_idx, val_idx, which_set='Train_Val') \n",
    "                                          for model_name, model in models.items()\n",
    "                                          for ratio in shuffle_ratio\n",
    "                                          for train_idx, val_idx in kf.split(X)\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'results/feature_shuffle/'\n",
    "create_directory(directory)\n",
    "\n",
    "results_shuffled_input = {\n",
    "    \"train\": results_shuffled_data_train, \n",
    "    \"val\":results_shuffled_data_val, \n",
    "    \"all\": results_shuffled_data_all,\n",
    "}\n",
    "\n",
    "for k,result in results_shuffled_input.items():\n",
    "    df_results = pd.DataFrame(result, columns=['Model', 'Noise level', 'AUC', 'Brier score', 'Prob true', 'Prob pred'])\n",
    "    df_results.to_csv(directory+k+'.csv', index=False)\n",
    "    df_results = process_df(df_results, n_folds)    \n",
    "    df_results.to_csv(directory+k+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subgroup analysis\n",
    "\n",
    "Here we consider different types of subgroup analysis: both within MIMIC-III and across MIMIC-IV. <br> For each analysis we consider either stratifying on one of the included feature (e.g., age) in the model or on a external variable (e.g., gender, icu unit).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'results/subgroups/'\n",
    "create_directory(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MIMIC-III"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**By gender**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgroup_analysis(model_name, model, train_idx, val_idx, stratify_on='gender'):\n",
    "\n",
    "    X_train, X_val = X.loc[train_idx], X.loc[val_idx]\n",
    "    y_train, y_val = y.loc[train_idx], y.loc[val_idx]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    stratified_perf = []\n",
    "    \n",
    "    for cat in mimic_3[stratify_on].dropna().unique():\n",
    "        X_val_strat = X_val.loc[mimic_3[stratify_on]==cat]\n",
    "        y_val_strat = y_val.loc[X_val_strat.index]\n",
    "        y_pred = model.predict_proba(X_val_strat)[:,1]\n",
    "        prob_true, prob_pred = calibration_curve(y_val_strat, y_pred)\n",
    "        stratified_perf.append([model_name, stratify_on, cat, roc_auc_score(y_score=y_pred, y_true=y_val_strat), brier_score_loss(y_true=y_val_strat, y_proba=y_pred), prob_true, prob_pred])\n",
    "        \n",
    "    return stratified_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_subgroup_m3_gender = Parallel(n_jobs=-1, verbose=1)(delayed(subgroup_analysis)(model_name, model, train_idx, val_idx, variable) \n",
    "                                          for model_name, model in models.items()\n",
    "                                          for variable in ['gender']\n",
    "                                          for train_idx, val_idx in kf.split(X)\n",
    "                                         )\n",
    "results_subgroup_m3_gender = [x for xs in results_subgroup_m3_gender for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_subgroup_m3_agegroup = Parallel(n_jobs=-1, verbose=1)(delayed(subgroup_analysis)(model_name, model, train_idx, val_idx, variable) \n",
    "                                          for model_name, model in models.items()\n",
    "                                          for variable in ['age_group']\n",
    "                                          for train_idx, val_idx in kf.split(X)\n",
    "                                         )\n",
    "results_subgroup_m3_agegroup = [x for xs in results_subgroup_m3_agegroup for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_subgroup_m3_icu_unit = Parallel(n_jobs=-1, verbose=1)(delayed(subgroup_analysis)(model_name, model, train_idx, val_idx, variable) \n",
    "                                          for model_name, model in models.items()\n",
    "                                          for variable in ['ICU_unit']\n",
    "                                          for train_idx, val_idx in kf.split(X)\n",
    "                                         )\n",
    "results_subgroup_m3_icu_unit = [x for xs in results_subgroup_m3_icu_unit for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_subgroup_analysis_m3 = {\n",
    "    \"m3_gender\": results_subgroup_m3_gender, \n",
    "    \"m3_age\": results_subgroup_m3_agegroup, \n",
    "    \"m3_icu_unit\": results_subgroup_m3_icu_unit,\n",
    "}\n",
    "\n",
    "for k,result in results_subgroup_analysis_m3.items():\n",
    "    df_results = pd.DataFrame(result, columns=['Model', 'Variable', 'Category', 'AUC', 'Brier score', 'Prob true', 'Prob pred'])\n",
    "    df_results.to_csv(directory+k+'.csv', index=False)\n",
    "    df_results = process_df(df_results, n_folds)    \n",
    "    df_results.to_csv(directory+k+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(model_name, model, X_tr, y_tr, df_test, stratify_on='gender'):\n",
    "\n",
    "    model.fit(X_tr, y_tr)\n",
    "\n",
    "    y_pred = model.predict_proba(df_test[X_tr.columns])[:,1]\n",
    "\n",
    "    stratified_perf = []\n",
    "    if stratify_on is not None:\n",
    "        for cat in df_test[stratify_on].dropna().unique():\n",
    "            X_eval_strat = df_test.loc[df_test[stratify_on]==cat][X_tr.columns]\n",
    "            y_eval_strat = df_test.loc[df_test[stratify_on]==cat]['hospital_mortality']\n",
    "            y_pred = model.predict_proba(X_eval_strat)[:,1]\n",
    "            prob_true, prob_pred = calibration_curve(y_eval_strat, y_pred)\n",
    "            stratified_perf.append([model_name, stratify_on, cat, roc_auc_score(y_score=y_pred, y_true=y_eval_strat), brier_score_loss(y_true=y_eval_strat, y_proba=y_pred), prob_true, prob_pred])\n",
    "        \n",
    "        return stratified_perf\n",
    "\n",
    "    prob_true, prob_pred = calibration_curve(df_test['hospital_mortality'], y_pred)\n",
    "    return model_name, roc_auc_score(y_score=y_pred, y_true=df_test['hospital_mortality']), prob_true, prob_pred    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_m4 = Parallel(n_jobs=-1, verbose=1)(delayed(train_evaluate)(model_name, model, X, y, mimic_4, stratify_on=None) \n",
    "                                          for model_name, model in models.items()\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_m4_gender = Parallel(n_jobs=-1, verbose=1)(delayed(train_evaluate)(model_name, model, X, y, mimic_4, stratify_on=variable) \n",
    "                                          for model_name, model in models.items()\n",
    "                                          for variable in ['gender']\n",
    "                                         )\n",
    "\n",
    "results_m4_gender = [x for xs in results_m4_gender for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_m4_age = Parallel(n_jobs=-1, verbose=1)(delayed(train_evaluate)(model_name, model, X, y, mimic_4, stratify_on=variable) \n",
    "                                          for model_name, model in models.items()\n",
    "                                          for variable in ['age_group']\n",
    "                                         )\n",
    "\n",
    "results_m4_age = [x for xs in results_m4_age for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_m4_icu_unit = Parallel(n_jobs=-1, verbose=1)(delayed(train_evaluate)(model_name, model, X, y, mimic_4, stratify_on=variable) \n",
    "                                          for model_name, model in models.items()\n",
    "                                          for variable in ['ICU_unit']\n",
    "                                         )\n",
    "\n",
    "results_m4_icu_unit = [x for xs in results_m4_icu_unit for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_m4_year = Parallel(n_jobs=-1, verbose=1)(delayed(train_evaluate)(model_name, model, X, y, mimic_4, stratify_on=variable) \n",
    "                                          for model_name, model in models.items()\n",
    "                                          for variable in ['anchor_year_group']\n",
    "                                         )\n",
    "\n",
    "results_m4_year = [x for xs in results_m4_year for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'results/m4/'\n",
    "create_directory(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_m4_all = {\n",
    "    \"m4_gender\": results_m4_gender,\n",
    "    \"m4_age\": results_m4_age, \n",
    "    \"m4_icu_unit\": results_m4_icu_unit, \n",
    "    \"m4_year\": results_m4_year,\n",
    "}\n",
    "\n",
    "for k,result in results_m4_all.items():\n",
    "    df_results = pd.DataFrame(result, columns=['Model', 'Variable', 'Category', 'AUC', 'Brier score', 'Prob true', 'Prob pred'])\n",
    "    df_results.to_csv(directory+k+'.csv', index=False)\n",
    "    df_results = process_df(df_results, n_folds)    \n",
    "    df_results.to_csv(directory+k+'.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
